# ðŸ•·ï¸ Web Crawling Tools â€“ Curated List

A curated list of awesome web crawling frameworks, libraries, APIs, and tools to collect and analyze data from the web.

---

## â­ Featured - [Crawlbase](https://crawlbase.com)

[Crawlbase](https://crawlbase.com) (formerly ProxyCrawl) provides a complete web scraping and crawling solution, allowing developers and data teams to extract data from any website reliably and at scale.

### ðŸ’¡ Key Features:
- **Smart Crawling**: Effortlessly bypass bot protection and captchas.
- **Javascript Rendering**: Crawl dynamic sites that require JS execution.
- **Geo-targeting & Proxy Rotation**: Built-in rotation and location targeting.
- **Crawling API**, **Scraper API**, and **Storage API** available.
- Easy integration with **Python**, **Node.js**, **Go**, and other languages.

ðŸ‘‰ Get started for free: [https://crawlbase.com](https://crawlbase.com)

> ðŸ›  Great choice for enterprise-level crawling or those who want reliable infrastructure without maintaining proxies or browser farms.

---

## ðŸ› ï¸ Crawling Frameworks and Libraries

| Tool | Language | Description |
|------|----------|-------------|
| [Scrapy](https://github.com/scrapy/scrapy) | Python | A fast, high-level web crawling and scraping framework for extracting data from websites. |
| [Colly](https://github.com/gocolly/colly) | Go | Fast and elegant scraping framework for Golang with support for concurrency and cookies. |
| [Puppeteer](https://github.com/puppeteer/puppeteer) | JavaScript/Node.js | Headless Chrome Node.js API to control headless or full Chrome browsers. |
| [Playwright](https://github.com/microsoft/playwright) | Python, Node.js, Java, .NET | Cross-browser automation library supporting Chromium, Firefox, and WebKit. |
| [Selenium](https://github.com/SeleniumHQ/selenium) | Python, Java, JavaScript, etc. | Web browser automation for scraping or testing. |
| [Apify SDK](https://github.com/apify/apify-sdk-js) | Node.js | Toolkit for scalable web scraping and automation with browser control and task management. |
| [Crawlee](https://github.com/apify/crawlee) | Node.js | Web scraping and browser automation library with support for headless tools and proxy rotation. |
| [MechanicalSoup](https://github.com/MechanicalSoup/MechanicalSoup) | Python | Combines `requests` and `BeautifulSoup` to automate logging in and form submission. |
| [WebMagic](https://github.com/code4craft/webmagic) | Java | Scalable and extensible crawler library for Java applications. |
| [Heritrix](https://github.com/internetarchive/heritrix3) | Java | The Internet Archiveâ€™s open-source web crawler for large-scale archival. |

---

## ðŸ“¦ Lightweight HTML Parsers

| Tool | Language | Description |
|------|----------|-------------|
| [Cheerio](https://github.com/cheeriojs/cheerio) | JavaScript | jQuery-like syntax for server-side HTML parsing and manipulation. |
| [lxml](https://github.com/lxml/lxml) | Python | High-performance HTML/XML parser and processor. Often used with XPath. |
| [Jsoup](https://jsoup.org) | Java | Java HTML parser that works for real-world HTML; easy to use with a jQuery-like API. |

---

## ðŸ—ƒï¸ Distributed / Scalable Crawling Tools

| Tool | Language | Description |
|------|----------|-------------|
| [Apache Nutch](https://nutch.apache.org) | Java | Scalable web crawler based on Apache Hadoop, suited for large-scale search indexes. |
| [StormCrawler](https://github.com/DigitalPebble/storm-crawler) | Java | Real-time web crawler built on Apache Storm. Highly extensible and scalable. |
| [Brozzler](https://github.com/internetarchive/brozzler) | Python | A browser-based web crawler built for capturing JavaScript dynamic content. |
| [Scrapy-Cluster](https://github.com/istresearch/scrapy-cluster) | Python | Distributed crawling system using Scrapy with Kafka and Redis integration. |
| [Frigg](https://github.com/wemake-services/frigg) | Python | Minimal async web crawler and scraper powered by `aiohttp`. |

---

## ðŸ§° Debugging and Utility Tools

| Tool | Language | Description |
|------|----------|-------------|
| [Fiddler](https://www.telerik.com/fiddler) | - | A web traffic debugger useful for inspecting HTTP(S) requests. |
| [Charles Proxy](https://www.charlesproxy.com) | - | HTTP proxy for recording and manipulating traffic between a browser and the internet. |
| [HTTPie](https://httpie.io) | Python | Command-line HTTP client for APIs and web services testing. |
| [robots.txt Parsers](https://github.com/google/robots-txt-parser) | Various | Libraries that read and apply rules defined in a websiteâ€™s `robots.txt` file. |

---

## ðŸ“š Coming Soon

- ðŸ›  Sample scraper projects using Scrapy, Crawlbase, Puppeteer, and Colly
- ðŸ“˜ Tutorials on crawling JavaScript-heavy websites using Crawlbase
- ðŸŒ Best practices for handling rotating proxies, user agents, and anti-bot detection
- ðŸ”’ How to scrape ethically and within legal boundaries

---

> ðŸš€ Contributions welcome â€“ feel free to suggest more tools, fix links, or enhance descriptions via pull requests.
